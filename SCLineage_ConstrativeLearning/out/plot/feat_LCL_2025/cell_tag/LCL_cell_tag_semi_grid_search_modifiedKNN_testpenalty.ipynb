{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the path to the main folder\n",
    "main_folder = \"/Users/apple/Desktop/KB/SCSeq_LineageBarcoding2/SCSeq_LineageBarcoding/SCLineage_ConstrativeLearning/main_semi_test\"\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(main_folder)\n",
    "\n",
    "from LCL_eval_final import LCL_Eval\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Paths & constants\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "INPUT_DIR  = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200/grid_search_testAsPenalty_1\"\n",
    "TRAIN_ANND = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad\"\n",
    "TEST_ANND  = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad\"\n",
    "num_knn = 30\n",
    "# load once\n",
    "adata_train = ad.read_h5ad(TRAIN_ANND)\n",
    "adata_test  = ad.read_h5ad(TEST_ANND)\n",
    "\n",
    "# flatten labels\n",
    "train_labels = adata_train.obs[\"clone_id\"].to_numpy()\n",
    "test_labels  = adata_test.obs[\"clone_id\"].to_numpy()\n",
    "\n",
    "records = []\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Loop over each hyperparam folder\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "for exp_name in sorted(os.listdir(INPUT_DIR)):\n",
    "    exp_path = os.path.join(INPUT_DIR, exp_name)\n",
    "    if not os.path.isdir(exp_path): \n",
    "        continue\n",
    "\n",
    "    # find embeddings\n",
    "    files = os.listdir(exp_path)\n",
    "    tr_file = next(f for f in files if f.startswith(\"scBaseEncoderFeat_Z\") and f.endswith(\".npy\"))\n",
    "    te_file = next(f for f in files if \"test_embedding\" in f or f.startswith(\"scBaseEncoderFeat_test\"))\n",
    "\n",
    "    train_emb = np.load(os.path.join(exp_path, tr_file))\n",
    "    test_emb  = np.load(os.path.join(exp_path, te_file))\n",
    "\n",
    "    # build combined AnnData\n",
    "    tr = adata_train.copy()\n",
    "    te = adata_test.copy()\n",
    "    tr.obsm[\"LCL_embedding\"] = train_emb\n",
    "    te.obsm[\"LCL_embedding\"] = test_emb\n",
    "    tr.obs[\"dataset\"] = \"train\"\n",
    "    te.obs[\"dataset\"] = \"test\"\n",
    "    adata_all = ad.concat([tr, te], axis=0, join=\"outer\")\n",
    "\n",
    "    # instantiate helper\n",
    "    plotter = LCL_Eval(\n",
    "        adata       = adata_all,\n",
    "        clone_key   = \"clone_id\",\n",
    "        dataset_key = \"dataset\",\n",
    "        num_top     = 5,\n",
    "        palette     = None,\n",
    "        umap_kwargs = {\"random_state\": 42}\n",
    "    )\n",
    "\n",
    "    # compute KNN stats\n",
    "    stats = plotter.evaluate_adjusted_knn(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = num_knn\n",
    "    )\n",
    "\n",
    "    # parse λ, unlab, bs\n",
    "    lam, unlab_s, bs_s = exp_name.split(\"_\")\n",
    "    lam   = float(lam.replace(\"lambda\",\"\"))\n",
    "    unlab = int(unlab_s.replace(\"unlab\",\"\"))\n",
    "    bs    = int(bs_s.replace(\"bs\",\"\"))\n",
    "\n",
    "    # unpack stats\n",
    "    to_4 = lambda x: round(x, 4)\n",
    "    tr_acc = stats[\"train\"][\"overall_accuracy\"]\n",
    "    tr_rank= stats[\"train\"][\"overall_avg_rank\"]\n",
    "    tr_qs  = stats[\"train\"][\"rank_quantiles\"]\n",
    "    te_acc = stats[\"test\"][\"overall_accuracy\"]\n",
    "    te_rank= stats[\"test\"][\"overall_avg_rank\"]\n",
    "    te_qs  = stats[\"test\"][\"rank_quantiles\"]\n",
    "\n",
    "    # plot #1: top‐5 clones\n",
    "    fig1, ax1 = plotter.plot_top_clones_umap(\n",
    "        figsize  = (7,7),\n",
    "        title    = f\"Top 5 Clones // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "        savepath = os.path.join(exp_path, f\"umap_top5clones_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "    )\n",
    "\n",
    "    # plot #2: test‐cell accuracy\n",
    "    fig2, ax2 = plotter.plot_test_accuracy_umap(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = num_knn,\n",
    "        figsize          = (7,7),\n",
    "        title            = f\"Test Accuracy // λ={lam}, unlab={unlab}, bs={bs}, k={num_knn}\",\n",
    "        savepath         = os.path.join(exp_path, f\"umap_testAccuracy_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "    )\n",
    "\n",
    "    # record exactly six stats + hyperparams\n",
    "    records.append({\n",
    "        \"lambda\":            lam,\n",
    "        \"unlabeled_per_batch\":unlab,\n",
    "        \"batch_size\":        bs,\n",
    "        \"train_overall_acc\": to_4(tr_acc),\n",
    "        \"train_overall_rank\":to_4(tr_rank),\n",
    "        \"train_q25\":         to_4(tr_qs[\"q25\"]),\n",
    "        \"train_q50\":         to_4(tr_qs[\"q50\"]),\n",
    "        \"train_q75\":         to_4(tr_qs[\"q75\"]),\n",
    "        \"test_overall_acc\":  to_4(te_acc),\n",
    "        \"test_overall_rank\": to_4(te_rank),\n",
    "        \"test_q25\":          to_4(te_qs[\"q25\"]),\n",
    "        \"test_q50\":          to_4(te_qs[\"q50\"]),\n",
    "        \"test_q75\":          to_4(te_qs[\"q75\"]),\n",
    "    })\n",
    "\n",
    "# build summary DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df)\n",
    "\n",
    "# optionally save\n",
    "out_csv = os.path.join(INPUT_DIR, f\"grid_search_summary_k{num_knn}.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\">>> Saved summary to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_k in [5, 10, 20, 30]:\n",
    "    # ───────────────────────────────────────────────────────────────────────────────\n",
    "    # Paths & constants\n",
    "    # ───────────────────────────────────────────────────────────────────────────────\n",
    "    INPUT_DIR  = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200/grid_search_testAsPenalty_1\"\n",
    "    TRAIN_ANND = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad\"\n",
    "    TEST_ANND  = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad\"\n",
    "    num_knn = num_k\n",
    "    # load once\n",
    "    adata_train = ad.read_h5ad(TRAIN_ANND)\n",
    "    adata_test  = ad.read_h5ad(TEST_ANND)\n",
    "\n",
    "    # flatten labels\n",
    "    train_labels = adata_train.obs[\"clone_id\"].to_numpy()\n",
    "    test_labels  = adata_test.obs[\"clone_id\"].to_numpy()\n",
    "\n",
    "    records = []\n",
    "\n",
    "    # ───────────────────────────────────────────────────────────────────────────────\n",
    "    # Loop over each hyperparam folder\n",
    "    # ───────────────────────────────────────────────────────────────────────────────\n",
    "    for exp_name in sorted(os.listdir(INPUT_DIR)):\n",
    "        exp_path = os.path.join(INPUT_DIR, exp_name)\n",
    "        if not os.path.isdir(exp_path): \n",
    "            continue\n",
    "\n",
    "        # find embeddings\n",
    "        files = os.listdir(exp_path)\n",
    "        tr_file = next(f for f in files if f.startswith(\"scBaseEncoderFeat_Z\") and f.endswith(\".npy\"))\n",
    "        te_file = next(f for f in files if \"test_embedding\" in f or f.startswith(\"scBaseEncoderFeat_test\"))\n",
    "\n",
    "        train_emb = np.load(os.path.join(exp_path, tr_file))\n",
    "        test_emb  = np.load(os.path.join(exp_path, te_file))\n",
    "\n",
    "        # build combined AnnData\n",
    "        tr = adata_train.copy()\n",
    "        te = adata_test.copy()\n",
    "        tr.obsm[\"LCL_embedding\"] = train_emb\n",
    "        te.obsm[\"LCL_embedding\"] = test_emb\n",
    "        tr.obs[\"dataset\"] = \"train\"\n",
    "        te.obs[\"dataset\"] = \"test\"\n",
    "        adata_all = ad.concat([tr, te], axis=0, join=\"outer\")\n",
    "\n",
    "        # instantiate helper\n",
    "        plotter = LCL_Eval(\n",
    "            adata       = adata_all,\n",
    "            clone_key   = \"clone_id\",\n",
    "            dataset_key = \"dataset\",\n",
    "            num_top     = 5,\n",
    "            palette     = None,\n",
    "            umap_kwargs = {\"random_state\": 42}\n",
    "        )\n",
    "\n",
    "        # compute KNN stats\n",
    "        stats = plotter.evaluate_adjusted_knn(\n",
    "            train_embeddings = train_emb,\n",
    "            train_labels     = train_labels,\n",
    "            test_embeddings  = test_emb,\n",
    "            test_labels      = test_labels,\n",
    "            k                = num_knn\n",
    "        )\n",
    "\n",
    "        # parse λ, unlab, bs\n",
    "        lam, unlab_s, bs_s = exp_name.split(\"_\")\n",
    "        lam   = float(lam.replace(\"lambda\",\"\"))\n",
    "        unlab = int(unlab_s.replace(\"unlab\",\"\"))\n",
    "        bs    = int(bs_s.replace(\"bs\",\"\"))\n",
    "\n",
    "        # unpack stats\n",
    "        to_4 = lambda x: round(x, 4)\n",
    "        tr_acc = stats[\"train\"][\"overall_accuracy\"]\n",
    "        tr_rank= stats[\"train\"][\"overall_avg_rank\"]\n",
    "        tr_qs  = stats[\"train\"][\"rank_quantiles\"]\n",
    "        tr_unique = stats[\"train\"][\"overall_avg_unique\"]\n",
    "        te_acc = stats[\"test\"][\"overall_accuracy\"]\n",
    "        te_rank= stats[\"test\"][\"overall_avg_rank\"]\n",
    "        te_unique = stats[\"test\"][\"overall_avg_unique\"]\n",
    "        te_qs  = stats[\"test\"][\"rank_quantiles\"]\n",
    "\n",
    "        # plot #1: top‐5 clones\n",
    "        fig1, ax1 = plotter.plot_top_clones_umap(\n",
    "            figsize  = (7,7),\n",
    "            title    = f\"Top 5 Clones // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "            savepath = os.path.join(exp_path, f\"umap_top5clones_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "        )\n",
    "\n",
    "        # plot #2: test‐cell accuracy\n",
    "        fig2, ax2 = plotter.plot_test_accuracy_umap(\n",
    "            train_embeddings = train_emb,\n",
    "            train_labels     = train_labels,\n",
    "            test_embeddings  = test_emb,\n",
    "            test_labels      = test_labels,\n",
    "            k                = num_knn,\n",
    "            figsize          = (7,7),\n",
    "            title            = f\"Test Accuracy // λ={lam}, unlab={unlab}, bs={bs}, k={num_knn}\",\n",
    "            savepath         = os.path.join(exp_path, f\"umap_testAccuracy_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "        )\n",
    "\n",
    "        # record exactly six stats + hyperparams\n",
    "        records.append({\n",
    "            \"lambda\":            lam,\n",
    "            \"unlabeled_per_batch\":unlab,\n",
    "            \"batch_size\":        bs,\n",
    "            \"train_overall_acc\": to_4(tr_acc),\n",
    "            \"train_overall_unique\":to_4(tr_unique),\n",
    "            \"train_overall_rank\":to_4(tr_rank),\n",
    "            \"train_q25\":         to_4(tr_qs[\"q25\"]),\n",
    "            \"train_q50\":         to_4(tr_qs[\"q50\"]),\n",
    "            \"train_q75\":         to_4(tr_qs[\"q75\"]),\n",
    "            \"test_overall_acc\":  to_4(te_acc),\n",
    "            \"test_overall_unique\": to_4(te_unique),\n",
    "            \"test_overall_rank\": to_4(te_rank),\n",
    "            \"test_q25\":          to_4(te_qs[\"q25\"]),\n",
    "            \"test_q50\":          to_4(te_qs[\"q50\"]),\n",
    "            \"test_q75\":          to_4(te_qs[\"q75\"]),\n",
    "        })\n",
    "\n",
    "    # build summary DataFrame\n",
    "    df = pd.DataFrame(records)\n",
    "    print(df)\n",
    "\n",
    "    # optionally save\n",
    "    out_csv = os.path.join(INPUT_DIR, f\"grid_search_summary_k{num_knn}.csv\")\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\">>> Saved summary to {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### anndata loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for grid_name in sorted(os.listdir(INPUT_DIR)):\n",
    "    grid_path = os.path.join(INPUT_DIR, grid_name)\n",
    "    if not os.path.isdir(grid_path): continue\n",
    "\n",
    "    for exp_name in sorted(os.listdir(grid_path)):\n",
    "        exp_path = os.path.join(grid_path, exp_name)\n",
    "        if not os.path.isdir(exp_path): continue\n",
    "\n",
    "        # find your two .npy files\n",
    "        files = os.listdir(exp_path)\n",
    "        tr_file = next(f for f in files if f.startswith(\"scBaseEncoderFeat_Z\") and f.endswith(\".npy\"))\n",
    "        te_file = next(f for f in files if \"test_embedding\" in f or f.startswith(\"scBaseEncoderFeat_test\"))\n",
    "\n",
    "        train_emb = np.load(os.path.join(exp_path, tr_file))\n",
    "        test_emb = np.load(os.path.join(exp_path, te_file))\n",
    "\n",
    "        # Original KNN evaluation\n",
    "        ev = LCL_eval.Eval(train_emb, TRAIN_ADATA)\n",
    "        orig_tr_acc = ev.KNN_train(n_neighbors=5)\n",
    "        orig_te_acc = ev.KNN_test(test_emb, TEST_ADATA, n_neighbors=30)\n",
    "\n",
    "        # Modified KNN classifier (sklearn-based)\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=30)\n",
    "        knn_model.fit(train_emb, train_labels)\n",
    "\n",
    "        preds_mod1_train, _, avg_rank_mod1_train, _ = adjusted_knn_predict_with_rank(\n",
    "            knn_model, train_labels, train_emb, train_labels, global_freq, k=30)\n",
    "        preds_mod1_test, _, avg_rank_mod1_test, _ = adjusted_knn_predict_with_rank(\n",
    "            knn_model, train_labels, test_emb, test_labels, global_freq, k=30)\n",
    "\n",
    "        mod1_tr_acc = (preds_mod1_train == train_labels).mean()\n",
    "        mod1_te_acc = (preds_mod1_test == test_labels).mean()\n",
    "\n",
    "        # Modified KNN classifier v2 (distance-based)\n",
    "        preds_mod2_train, _, avg_rank_mod2_train, _ = adjusted_knn_predict_with_rank_v2(\n",
    "            train_emb, train_labels, train_emb, train_labels, global_freq, k=30)\n",
    "        preds_mod2_test, _, avg_rank_mod2_test, _ = adjusted_knn_predict_with_rank_v2(\n",
    "            train_emb, train_labels, test_emb, test_labels, global_freq, k=30)\n",
    "\n",
    "        mod2_tr_acc = (preds_mod2_train == train_labels).mean()\n",
    "        mod2_te_acc = (preds_mod2_test == test_labels).mean()\n",
    "\n",
    "        # parse hyperparams out of exp_name\n",
    "        lam, unlab, bs = exp_name.split(\"_\")\n",
    "        lam = float(lam.replace(\"lambda\", \"\"))\n",
    "        unlab = int(unlab.replace(\"unlab\", \"\"))\n",
    "        bs = int(bs.replace(\"bs\", \"\"))\n",
    "\n",
    "        # Record results\n",
    "        records.append({\n",
    "            \"grid\": grid_name,\n",
    "            \"lambda\": lam,\n",
    "            \"unlabeled\": unlab,\n",
    "            \"batch_size\": bs,\n",
    "\n",
    "            # Original KNN accuracy\n",
    "            \"orig_train_acc\": orig_tr_acc,\n",
    "            \"orig_test_acc\": orig_te_acc,\n",
    "\n",
    "            # Modified KNN v1 accuracy\n",
    "            \"mod1_train_acc\": mod1_tr_acc,\n",
    "            \"mod1_test_acc\": mod1_te_acc,\n",
    "            \"mod1_avg_rank_train\": avg_rank_mod1_train,\n",
    "            \"mod1_avg_rank_test\": avg_rank_mod1_test,\n",
    "\n",
    "            # Modified KNN v2 accuracy\n",
    "            \"mod2_train_acc\": mod2_tr_acc,\n",
    "            \"mod2_test_acc\": mod2_te_acc,\n",
    "            \"mod2_avg_rank_train\": avg_rank_mod2_train,\n",
    "            \"mod2_avg_rank_test\": avg_rank_mod2_test\n",
    "        })\n",
    "\n",
    "# Create summary DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"knn_evaluation_summary.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad')\n",
    "adata_test  = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad')\n",
    "\n",
    "INPUT_DIR = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200/feat_semi_sup_grid_search\"\n",
    "\n",
    "train_semi_10 = np.load(INPUT_DIR+'/grid_search_3/lambda0.3_unlab15_bs150/scBaseEncoderFeat_Z_bs150_tau0.5.npy')\n",
    "test_semi_10 = np.load(INPUT_DIR+'/grid_search_3/lambda0.3_unlab15_bs150/test_embedding.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad')\n",
    "adata_test  = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad')\n",
    "\n",
    "INPUT_DIR = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200\"\n",
    "\n",
    "train_semi_10 = np.load(INPUT_DIR+'/lambda0.01_unlab15_bs150_testAsPenalty/scBaseEncoderFeat_Z_bs150_tau0.5.npy')\n",
    "test_semi_10 = np.load(INPUT_DIR+'/lambda0.01_unlab15_bs150_testAsPenalty/test_embedding.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train.obsm[\"LCL_embedding_semi_10\"] = train_semi_10\n",
    "adata_test.obsm[\"LCL_embedding_semi_10\"] = test_semi_10\n",
    "\n",
    "adata_train.obs[\"dataset\"] = \"train\"\n",
    "adata_test.obs[\"dataset\"] = \"test\"\n",
    "\n",
    "adata = ad.concat([adata_train, adata_test], axis=0, join='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "embedding_umap = reducer.fit_transform(adata.obsm[\"LCL_embedding_semi_10\"])\n",
    "\n",
    "adata.obsm[\"X_umap\"] = embedding_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Count number of cells per lineage\n",
    "clone_counts = adata.obs[\"clone_id\"].value_counts()\n",
    "\n",
    "# Get the top 5 largest lineages\n",
    "top_5_clones = clone_counts.index[:5]\n",
    "\n",
    "# Assign 'Other' to all lineages except the top 5\n",
    "adata.obs[\"clone_group\"] = adata.obs[\"clone_id\"].apply(lambda x: x if x in top_5_clones else \"Other\")\n",
    "\n",
    "# Convert to categorical\n",
    "adata.obs[\"clone_group\"] = adata.obs[\"clone_group\"].astype(\"category\")\n",
    "\n",
    "# Print for verification\n",
    "print(adata.obs[\"clone_group\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_umap(adata, colormap=\"tab10\"):\n",
    "    \"\"\"\n",
    "    Plots UMAP with:\n",
    "    - Top 5 clones in distinct colors (plotted on top)\n",
    "    - Other clones in gray with lower opacity\n",
    "    - Train cells as dots, Test cells as crosses\n",
    "    - Larger marker size for top 5 clones\n",
    "    \"\"\"\n",
    "    umap_coords = adata.obsm[\"X_umap\"]\n",
    "\n",
    "    # Extract train and test indices\n",
    "    train_idx = adata.obs[\"dataset\"] == \"train\"\n",
    "    test_idx = adata.obs[\"dataset\"] == \"test\"\n",
    "\n",
    "    # Get unique clone groups\n",
    "    unique_clones = adata.obs[\"clone_group\"].cat.categories\n",
    "\n",
    "    # Define a colormap for the top 5 clones, others in gray\n",
    "    colors = plt.get_cmap(colormap)(range(len(unique_clones) - 1))  # Leave space for gray\n",
    "    color_map = dict(zip(unique_clones[:-1], colors))  # Map top 5 clones\n",
    "    color_map[\"Other\"] = \"gray\"  # Set 'Other' to gray\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # **Step 1**: Plot \"Other\" cells first (background with low opacity)\n",
    "    idx_train_other = (adata.obs[\"clone_group\"] == \"Other\") & train_idx\n",
    "    idx_test_other = (adata.obs[\"clone_group\"] == \"Other\") & test_idx\n",
    "\n",
    "    plt.scatter(umap_coords[idx_train_other, 0], umap_coords[idx_train_other, 1], \n",
    "                color=color_map[\"Other\"], s=8, marker=\".\", alpha=0.2, label=\"Train Other\")  # Lower opacity\n",
    "\n",
    "    plt.scatter(umap_coords[idx_test_other, 0], umap_coords[idx_test_other, 1], \n",
    "                color=color_map[\"Other\"], s=12, marker=\"x\", alpha=0.2, label=\"Test Other\")  # Lower opacity\n",
    "\n",
    "    # **Step 2**: Plot top 5 clones on top (larger size)\n",
    "    for clone in unique_clones[:-1]:  # Skip \"Other\"\n",
    "        idx_train = (adata.obs[\"clone_group\"] == clone) & train_idx\n",
    "        idx_test = (adata.obs[\"clone_group\"] == clone) & test_idx\n",
    "\n",
    "        # Train: Dots\n",
    "        plt.scatter(umap_coords[idx_train, 0], umap_coords[idx_train, 1], \n",
    "                    color=color_map[clone], s=30, marker=\".\", alpha=0.8, label=f\"Train {clone}\")  # Bigger size\n",
    "\n",
    "        # Test: Crosses\n",
    "        plt.scatter(umap_coords[idx_test, 0], umap_coords[idx_test, 1], \n",
    "                    color=color_map[clone], s=40, marker=\"x\", alpha=0.9, label=f\"Test {clone}\")  # Bigger size\n",
    "\n",
    "    plt.xlabel(\"UMAP1\")\n",
    "    plt.ylabel(\"UMAP2\")\n",
    "    plt.title(\"UMAP Projection - Top 5 Clones Highlighted\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Run the function to plot\n",
    "plot_umap(adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_umap_with_lineages(adata, n_top_lineages=5, colormap=\"tab10\"):\n",
    "    \"\"\"\n",
    "    Plots UMAP from `adata.obsm[\"X_umap\"]` with:\n",
    "    - Top N clones in distinct colors (plotted on top)\n",
    "    - Other clones in gray with lower opacity\n",
    "    - Train cells as dots, Test cells as crosses\n",
    "    \n",
    "    Parameters:\n",
    "    - adata (AnnData): AnnData object with precomputed UMAP in `.obsm[\"X_umap\"]`\n",
    "    - n_top_lineages (int): Number of largest lineages to highlight in the plot\n",
    "    - colormap (str): Matplotlib colormap for the distinct top N lineages\n",
    "    \n",
    "    Output:\n",
    "    - A UMAP scatter plot (does NOT modify `adata`)\n",
    "    \"\"\"\n",
    "\n",
    "    ### **1️⃣ Check If Required Fields Exist**\n",
    "    if \"X_umap\" not in adata.obsm:\n",
    "        raise ValueError(\"UMAP coordinates missing! Ensure `adata.obsm['X_umap']` is computed.\")\n",
    "    \n",
    "    if \"LCL_embedding_semi_10\" not in adata.obsm:\n",
    "        raise ValueError(\"Contrastive learning embeddings missing! Ensure `adata.obsm['LCL_embedding_dim10']` exists.\")\n",
    "    \n",
    "    if \"clone_id\" not in adata.obs:\n",
    "        raise ValueError(\"Clone ID column missing! Ensure `adata.obs['clone_id']` exists.\")\n",
    "    \n",
    "    if \"dataset\" not in adata.obs:\n",
    "        raise ValueError(\"Dataset column missing! Ensure `adata.obs['dataset']` exists with 'train' and 'test' values.\")\n",
    "\n",
    "    ### **2️⃣ Identify the Top N Largest Lineages**\n",
    "    print(f\"Identifying the top {n_top_lineages} largest lineages...\")\n",
    "    clone_counts = adata.obs[\"clone_id\"].value_counts()\n",
    "    top_n_clones = clone_counts.index[:n_top_lineages]\n",
    "\n",
    "    # Assign \"Other\" to all but the top N lineages\n",
    "    adata.obs[\"clone_group\"] = adata.obs[\"clone_id\"].apply(lambda x: x if x in top_n_clones else \"Other\")\n",
    "    \n",
    "    # Convert to categorical for easy plotting\n",
    "    adata.obs[\"clone_group\"] = adata.obs[\"clone_group\"].astype(\"category\")\n",
    "\n",
    "    ### **3️⃣ Plot UMAP with Custom Formatting**\n",
    "    print(\"Plotting UMAP with lineage-specific colors and train/test markers...\")\n",
    "\n",
    "    umap_coords = adata.obsm[\"X_umap\"]\n",
    "    train_idx = adata.obs[\"dataset\"] == \"train\"\n",
    "    test_idx = adata.obs[\"dataset\"] == \"test\"\n",
    "    \n",
    "    unique_clones = adata.obs[\"clone_group\"].cat.categories\n",
    "\n",
    "    # Define a colormap for the top N clones, others in gray\n",
    "    colors = plt.get_cmap(colormap)(range(len(unique_clones) - 1))  # Leave space for gray\n",
    "    color_map = dict(zip(unique_clones[:-1], colors))  # Map top N clones\n",
    "    color_map[\"Other\"] = \"gray\"  # Set 'Other' to gray\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # **Step 1**: Plot \"Other\" cells first (background with low opacity)\n",
    "    idx_train_other = (adata.obs[\"clone_group\"] == \"Other\") & train_idx\n",
    "    idx_test_other = (adata.obs[\"clone_group\"] == \"Other\") & test_idx\n",
    "\n",
    "    plt.scatter(umap_coords[idx_train_other, 0], umap_coords[idx_train_other, 1], \n",
    "                color=color_map[\"Other\"], s=8, marker=\".\", alpha=0.2, label=\"Train Other\")\n",
    "\n",
    "    plt.scatter(umap_coords[idx_test_other, 0], umap_coords[idx_test_other, 1], \n",
    "                color=color_map[\"Other\"], s=8, marker=\"x\", alpha=0.2, label=\"Test Other\")\n",
    "\n",
    "    # **Step 2**: Plot top N clones on top (larger size)\n",
    "    for clone in unique_clones[:-1]:  # Skip \"Other\"\n",
    "        idx_train = (adata.obs[\"clone_group\"] == clone) & train_idx\n",
    "        idx_test = (adata.obs[\"clone_group\"] == clone) & test_idx\n",
    "\n",
    "        # Train: Dots\n",
    "        plt.scatter(umap_coords[idx_train, 0], umap_coords[idx_train, 1], \n",
    "                    color=color_map[clone], s=40, marker=\".\", alpha=0.8, label=f\"Train {clone}\")\n",
    "\n",
    "        # Test: Crosses\n",
    "        plt.scatter(umap_coords[idx_test, 0], umap_coords[idx_test, 1], \n",
    "                    color=color_map[clone], s=40, marker=\"x\", alpha=1, label=f\"Test {clone}\")\n",
    "\n",
    "    plt.xlabel(\"UMAP1\")\n",
    "    plt.ylabel(\"UMAP2\")\n",
    "    plt.title(f\"UMAP Projection - Top {n_top_lineages} Clones Highlighted\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_umap_with_lineages(adata, n_top_lineages=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(embedding_umap[:,0],embedding_umap[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding_umap[:10147,0],embedding_umap[:10147,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(embedding_umap[10148:,0],embedding_umap[10148:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_semi_10_train = LCL_eval.Eval(train_semi_10, adata_train)\n",
    "eval_semi_10_train.plot_umap_top_lin(\"semi-supervised learning with 5 unlabeled data\")\n",
    "eval_semi_10_train.KNN_train()\n",
    "score_10_train = eval_semi_10_train.calculate_calinski_harabasz_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_semi_10_test = LCL_eval.Eval(test_semi_10, adata_test)\n",
    "eval_semi_10_test.plot_umap_top_lin(\"semi-supervised learning with 5 unlabeled data\")\n",
    "score_semi_10_test = eval_semi_10_test.calculate_calinski_harabasz_score()\n",
    "eval_semi_10_train.KNN_test(test_semi_10, adata_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_train = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad')\n",
    "adata_test  = ad.read_h5ad('/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad')\n",
    "\n",
    "INPUT_DIR = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200\"\n",
    "\n",
    "train_semi_001 = np.load(INPUT_DIR+'/lambda0.01_unlab15_bs150_testAsPenalty/scBaseEncoderFeat_Z_bs150_tau0.5.npy')\n",
    "test_semi_001 = np.load(INPUT_DIR+'/lambda0.01_unlab15_bs150_testAsPenalty/test_embedding.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev = LCL_eval.Eval(train_semi_001, adata_train)\n",
    "tr_acc = ev.KNN_train(n_neighbors=5)\n",
    "te_acc = ev.KNN_test(test_semi_001, adata_test, n_neighbors=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
