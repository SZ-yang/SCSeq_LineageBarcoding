{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the path to the main folder\n",
    "main_folder = \"/Users/apple/Desktop/KB/SCSeq_LineageBarcoding2/SCSeq_LineageBarcoding/SCLineage_ConstrativeLearning/main_semi_test\"\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(main_folder)\n",
    "\n",
    "from LCL_eval_final import LCL_Eval\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Paths & constants\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "INPUT_DIR  = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200/grid_search_testAsPenalty_1\"\n",
    "TRAIN_ANND = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad\"\n",
    "TEST_ANND  = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad\"\n",
    "num_knn = 30\n",
    "# load once\n",
    "adata_train = ad.read_h5ad(TRAIN_ANND)\n",
    "adata_test  = ad.read_h5ad(TEST_ANND)\n",
    "\n",
    "# flatten labels\n",
    "train_labels = adata_train.obs[\"clone_id\"].to_numpy()\n",
    "test_labels  = adata_test.obs[\"clone_id\"].to_numpy()\n",
    "\n",
    "records = []\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Loop over each hyperparam folder\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "for exp_name in sorted(os.listdir(INPUT_DIR)):\n",
    "    exp_path = os.path.join(INPUT_DIR, exp_name)\n",
    "    if not os.path.isdir(exp_path): \n",
    "        continue\n",
    "\n",
    "    # find embeddings\n",
    "    files = os.listdir(exp_path)\n",
    "    tr_file = next(f for f in files if f.startswith(\"scBaseEncoderFeat_Z\") and f.endswith(\".npy\"))\n",
    "    te_file = next(f for f in files if \"test_embedding\" in f or f.startswith(\"scBaseEncoderFeat_test\"))\n",
    "\n",
    "    train_emb = np.load(os.path.join(exp_path, tr_file))\n",
    "    test_emb  = np.load(os.path.join(exp_path, te_file))\n",
    "\n",
    "    # build combined AnnData\n",
    "    tr = adata_train.copy()\n",
    "    te = adata_test.copy()\n",
    "    tr.obsm[\"LCL_embedding\"] = train_emb\n",
    "    te.obsm[\"LCL_embedding\"] = test_emb\n",
    "    tr.obs[\"dataset\"] = \"train\"\n",
    "    te.obs[\"dataset\"] = \"test\"\n",
    "    adata_all = ad.concat([tr, te], axis=0, join=\"outer\")\n",
    "\n",
    "    # instantiate helper\n",
    "    plotter = LCL_Eval(\n",
    "        adata       = adata_all,\n",
    "        clone_key   = \"clone_id\",\n",
    "        dataset_key = \"dataset\",\n",
    "        num_top     = 5,\n",
    "        palette     = None,\n",
    "        umap_kwargs = {\"random_state\": 42}\n",
    "    )\n",
    "\n",
    "    # compute KNN stats\n",
    "    stats = plotter.evaluate_adjusted_knn(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = num_knn\n",
    "    )\n",
    "\n",
    "    # parse λ, unlab, bs\n",
    "    lam, unlab_s, bs_s = exp_name.split(\"_\")\n",
    "    lam   = float(lam.replace(\"lambda\",\"\"))\n",
    "    unlab = int(unlab_s.replace(\"unlab\",\"\"))\n",
    "    bs    = int(bs_s.replace(\"bs\",\"\"))\n",
    "\n",
    "    # unpack stats\n",
    "    to_4 = lambda x: round(x, 4)\n",
    "    tr_acc = stats[\"train\"][\"overall_accuracy\"]\n",
    "    tr_rank= stats[\"train\"][\"overall_avg_rank\"]\n",
    "    tr_qs  = stats[\"train\"][\"rank_quantiles\"]\n",
    "    te_acc = stats[\"test\"][\"overall_accuracy\"]\n",
    "    te_rank= stats[\"test\"][\"overall_avg_rank\"]\n",
    "    te_qs  = stats[\"test\"][\"rank_quantiles\"]\n",
    "\n",
    "    # plot #1: top‐5 clones\n",
    "    fig1, ax1 = plotter.plot_top_clones_umap(\n",
    "        figsize  = (7,7),\n",
    "        title    = f\"Top 5 Clones // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "        savepath = os.path.join(exp_path, f\"umap_top5clones_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "    )\n",
    "\n",
    "    # plot #2: test‐cell accuracy\n",
    "    fig2, ax2 = plotter.plot_test_accuracy_umap(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = num_knn,\n",
    "        figsize          = (7,7),\n",
    "        title            = f\"Test Accuracy // λ={lam}, unlab={unlab}, bs={bs}, k={num_knn}\",\n",
    "        savepath         = os.path.join(exp_path, f\"umap_testAccuracy_lambda{lam}_unlab{unlab}_bs{bs}_k{num_knn}.png\")\n",
    "    )\n",
    "\n",
    "    # record exactly six stats + hyperparams\n",
    "    records.append({\n",
    "        \"lambda\":            lam,\n",
    "        \"unlabeled_per_batch\":unlab,\n",
    "        \"batch_size\":        bs,\n",
    "        \"train_overall_acc\": to_4(tr_acc),\n",
    "        \"train_overall_rank\":to_4(tr_rank),\n",
    "        \"train_q25\":         to_4(tr_qs[\"q25\"]),\n",
    "        \"train_q50\":         to_4(tr_qs[\"q50\"]),\n",
    "        \"train_q75\":         to_4(tr_qs[\"q75\"]),\n",
    "        \"test_overall_acc\":  to_4(te_acc),\n",
    "        \"test_overall_rank\": to_4(te_rank),\n",
    "        \"test_q25\":          to_4(te_qs[\"q25\"]),\n",
    "        \"test_q50\":          to_4(te_qs[\"q50\"]),\n",
    "        \"test_q75\":          to_4(te_qs[\"q75\"]),\n",
    "    })\n",
    "\n",
    "# build summary DataFrame\n",
    "df = pd.DataFrame(records)\n",
    "print(df)\n",
    "\n",
    "# optionally save\n",
    "out_csv = os.path.join(INPUT_DIR, f\"grid_search_summary_k{num_knn}.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\">>> Saved summary to {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import anndata as ad\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Define the path to the main folder\n",
    "main_folder = \"/Users/apple/Desktop/KB/SCSeq_LineageBarcoding2/SCSeq_LineageBarcoding/SCLineage_ConstrativeLearning/main_semi_test\"\n",
    "\n",
    "# Add it to sys.path\n",
    "sys.path.append(main_folder)\n",
    "\n",
    "from LCL_eval_final_final_final import LCL_Eval\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/scvi-env/lib/python3.9/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n",
      "/opt/anaconda3/envs/scvi-env/lib/python3.9/site-packages/threadpoolctl.py:1010: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m\n\u001b[1;32m     53\u001b[0m stats \u001b[38;5;241m=\u001b[39m plotter\u001b[38;5;241m.\u001b[39mevaluate_adjusted_knn(\n\u001b[1;32m     54\u001b[0m     train_embeddings \u001b[38;5;241m=\u001b[39m train_emb,\n\u001b[1;32m     55\u001b[0m     train_labels     \u001b[38;5;241m=\u001b[39m train_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     58\u001b[0m     k                \u001b[38;5;241m=\u001b[39m NUM_NEIGHBORS\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# parse λ, unlab, bs from folder name \"lambda0.01_unlab15_bs150_testAsPenalty\"\u001b[39;00m\n\u001b[0;32m---> 62\u001b[0m lam_s, unlab_s, bs_s, _ \u001b[38;5;241m=\u001b[39m exp_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m lam   \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(lam_s\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlambda\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     64\u001b[0m unlab \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(unlab_s\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlab\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "\n",
    "import scanpy as sc\n",
    "\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "# Paths & constants\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "INPUT_DIR     = \"/Users/apple/Desktop/KB/data/feat_LCL_2025/Larry_top200/grid_search_testAsPenalty_1\"\n",
    "TRAIN_ANND    = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_train.h5ad\"\n",
    "TEST_ANND     = \"/Users/apple/Desktop/KB/data/LarryData/train_test/Larry_200_test.h5ad\"\n",
    "NUM_NEIGHBORS = 30\n",
    "\n",
    "# load the two AnnDatas once\n",
    "adata_train = sc.read_h5ad(TRAIN_ANND)\n",
    "adata_test  = sc.read_h5ad(TEST_ANND)\n",
    "\n",
    "train_labels = adata_train.obs[\"clone_id\"].to_numpy()\n",
    "test_labels  = adata_test.obs[\"clone_id\"].to_numpy()\n",
    "\n",
    "records = []\n",
    "\n",
    "for exp_name in sorted(os.listdir(INPUT_DIR)):\n",
    "    exp_path = os.path.join(INPUT_DIR, exp_name)\n",
    "    if not os.path.isdir(exp_path):\n",
    "        continue\n",
    "\n",
    "    # locate embeddings\n",
    "    files   = os.listdir(exp_path)\n",
    "    tr_file = next(f for f in files if f.startswith(\"scBaseEncoderFeat_Z\") and f.endswith(\".npy\"))\n",
    "    te_file = next(f for f in files if \"test_embedding\" in f)\n",
    "\n",
    "    train_emb = np.load(os.path.join(exp_path, tr_file))\n",
    "    test_emb  = np.load(os.path.join(exp_path, te_file))\n",
    "\n",
    "    # stitch into one AnnData\n",
    "    tr = adata_train.copy()\n",
    "    te = adata_test.copy()\n",
    "    tr.obsm[\"LCL_embedding\"] = train_emb\n",
    "    te.obsm[\"LCL_embedding\"]  = test_emb\n",
    "    tr.obs[\"dataset\"] = \"train\"\n",
    "    te.obs[\"dataset\"] = \"test\"\n",
    "    adata_all = sc.concat([tr, te], axis=0, join=\"outer\")\n",
    "\n",
    "    # instantiate evaluator\n",
    "    plotter = LCL_Eval(\n",
    "        adata       = adata_all,\n",
    "        clone_key   = \"clone_id\",\n",
    "        dataset_key = \"dataset\",\n",
    "        num_top     = 5,\n",
    "        palette     = None,\n",
    "        umap_kwargs = {\"random_state\": 42}\n",
    "    )\n",
    "\n",
    "    # compute stats\n",
    "    stats = plotter.evaluate_adjusted_knn(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = NUM_NEIGHBORS\n",
    "    )\n",
    "\n",
    "    # parse λ, unlab, bs from folder name \"lambda0.01_unlab15_bs150_testAsPenalty\"\n",
    "    lam_s, unlab_s, bs_s = exp_name.split(\"_\")\n",
    "    lam   = float(lam_s.replace(\"lambda\",\"\"))\n",
    "    unlab = int(unlab_s.replace(\"unlab\",\"\"))\n",
    "    bs    = int(bs_s.replace(\"bs\",\"\"))\n",
    "\n",
    "    # unpack train stats\n",
    "    tr_acc    = stats[\"train\"][\"accuracy\"]\n",
    "    tr_unique = stats[\"train\"][\"avg_unique\"]\n",
    "\n",
    "    # unpack test stats\n",
    "    te_acc    = stats[\"test\"][\"accuracy\"]\n",
    "    te_cont   = stats[\"test\"][\"containment_rate\"]\n",
    "    te_rank   = stats[\"test\"][\"overall_avg_rank\"]\n",
    "    te_unique = stats[\"test\"][\"avg_unique\"]\n",
    "    uq        = stats[\"test\"][\"unique_quantiles\"]\n",
    "    aq        = stats[\"test\"][\"accuracy_quantiles\"]\n",
    "\n",
    "    # ─── Plot #1: Top‐5 clones UMAP ───────────────────────────────────────────────\n",
    "    fig1, ax1 = plotter.plot_top_clones_umap(\n",
    "        figsize  = (7,7),\n",
    "        title    = f\"Top‐5 Clones // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "        savepath = os.path.join(\n",
    "            exp_path,\n",
    "            f\"umap_top5_λ{lam}_unlab{unlab}_bs{bs}.png\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ─── Plot #2: Test‐cell accuracy UMAP ─────────────────────────────────────────\n",
    "    fig2, ax2 = plotter.plot_test_accuracy_umap(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = NUM_NEIGHBORS,\n",
    "        figsize          = (7,7),\n",
    "        title            = f\"Test Acc // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "        savepath         = os.path.join(\n",
    "            exp_path,\n",
    "            f\"umap_testAcc_λ{lam}_unlab{unlab}_bs{bs}.png\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ─── Plot #3: Lineage size vs. test accuracy ─────────────────────────────────\n",
    "    fig3, ax3 = plotter.plot_lineage_size_vs_accuracy(\n",
    "        train_embeddings = train_emb,\n",
    "        train_labels     = train_labels,\n",
    "        test_embeddings  = test_emb,\n",
    "        test_labels      = test_labels,\n",
    "        k                = NUM_NEIGHBORS,\n",
    "        figsize          = (6,6),\n",
    "        title            = f\"Lineage Size vs Acc // λ={lam}, unlab={unlab}, bs={bs}\",\n",
    "        savepath         = os.path.join(\n",
    "            exp_path,\n",
    "            f\"lineageSize_vs_acc_λ{lam}_unlab{unlab}_bs{bs}.png\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # collect into records\n",
    "    records.append({\n",
    "        \"lambda\":               lam,\n",
    "        \"unlabeled_per_batch\":  unlab,\n",
    "        \"batch_size\":           bs,\n",
    "\n",
    "        \"train_overall_acc\":    round(tr_acc,4),\n",
    "        \"train_overall_unique\": round(tr_unique,4),\n",
    "\n",
    "        \"test_overall_acc\":     round(te_acc,4),\n",
    "        \"test_containment\":     round(te_cont,4),\n",
    "        \"test_overall_rank\":    round(te_rank,4),\n",
    "        \"test_overall_unique\":  round(te_unique,4),\n",
    "\n",
    "        # unique‐quantiles\n",
    "        \"test_unique_q0\":       uq[\"q0\"],\n",
    "        \"test_unique_q25\":      uq[\"q25\"],\n",
    "        \"test_unique_q50\":      uq[\"q50\"],\n",
    "        \"test_unique_q75\":      uq[\"q75\"],\n",
    "        \"test_unique_q100\":     uq[\"q100\"],\n",
    "\n",
    "        # accuracy‐quantiles\n",
    "        \"test_accuracy_q0\":     aq[\"q0\"],\n",
    "        \"test_accuracy_q25\":    aq[\"q25\"],\n",
    "        \"test_accuracy_q50\":    aq[\"q50\"],\n",
    "        \"test_accuracy_q75\":    aq[\"q75\"],\n",
    "        \"test_accuracy_q100\":   aq[\"q100\"],\n",
    "    })\n",
    "\n",
    "# build & save summary\n",
    "df = pd.DataFrame(records)\n",
    "print(df)\n",
    "\n",
    "out_csv = os.path.join(INPUT_DIR, f\"grid_search_summary_k{NUM_NEIGHBORS}.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(f\">>> Saved summary to {out_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scvi-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
