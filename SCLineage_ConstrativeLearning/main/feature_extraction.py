import torch
import numpy as np
from torch.utils.data import DataLoader, TensorDataset
import anndata as ad
from scContrastiveLearning_Model import AddProjectionMLP, ContrastiveLoss
from scContrastiveLearning_Main_709_ckpt_epoch import scContraLearn, load_checkpoint, Hparams, get_args  # Import necessary parts from your main script

def evaluate_model(checkpoint_path, adata_path, config):
    # Initialize the model
    model = scContraLearn(config)
    
    # Load the model from the checkpoint
    model = load_checkpoint(model, checkpoint_path)
    
    # Set the model to evaluation mode
    model.eval()
    
    # Determine device: Use GPU if available, otherwise CPU
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    # Load new data for evaluation
    adata_new = ad.read_h5ad(adata_path)
    count_matrix_new = adata_new.X
    try:
        count_matrix_new = count_matrix_new.toarray()
    except AttributeError:
        pass
    
    count_matrix_th_new = torch.from_numpy(count_matrix_new)
    dataset_new = TensorDataset(count_matrix_th_new)
    new_data_loader = DataLoader(dataset_new, batch_size=config.batch_size, shuffle=False, num_workers=4, drop_last=False)

    # Run evaluation on the new data
    all_features = []
    for batch in new_data_loader:
        data = batch[0].to(device)  # Move data to the same device as the model
        with torch.no_grad():  # No need to compute gradients
            features = model.model.get_features(data)
        all_features.append(features.cpu().detach().numpy())  # Detach and convert to NumPy
    
    # Concatenate all features into a single numpy array
    all_features = np.concatenate(all_features, axis=0)
    
    print("Shape of the feature representation generated by the base encoder:", all_features.shape)
    
    # Save the complete set of features
    np.save(config.out_dir + "/test_embedding.npy", all_features)
    
    return all_features


if __name__ == "__main__":
    # Parse arguments
    args = get_args()
    
    # Create the configuration object
    config = Hparams(args)

    # Path to the checkpoint file
    checkpoint_path = args.resume_from_checkpoint
    
    # Path to the new data (AnnData file)
    adata_path = args.inputFilePath
    
    # Evaluate the model
    features = evaluate_model(checkpoint_path, adata_path, config)
    
