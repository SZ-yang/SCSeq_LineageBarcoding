'''
Train_test part for scContrastiveLearning model
(next version of scContrastiveLearning_ver3.py)

1. updated with the train validation set 
2. updated with the organization of hyper parameters
3. updated with main model with validation loss

Past updates 'till Ver 3:
1. updated with the feature representation generated by the base encoder
2. updated the new dataloader that can return the lineage information
3. updated with the feature representation of total 41201 cells generated by the base encoder
4. change the optimizer from Adam to AdamW
5. add an additional figure: train_config.batch_seed to control the batch generator 
'''

# general package
import time
import random
import tempfile
import os
import numpy as np
import anndata as ad

# deep learning package
import torch
from torch.multiprocessing import cpu_count
from torch.optim import AdamW 

import pytorch_lightning as pl
import torch.nn.functional as F
from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR
from torch.utils.data import TensorDataset
from pytorch_lightning.callbacks import Callback

# self-written packages
from scContrastiveLearning_Model import AddProjectionMLP, ContrastiveLoss
import Larry_Dataloader as LD
import SCDataset as ds

#--------------------------------------------------for terminal use--------------------------------------------------
import argparse

def get_args():
    parser = argparse.ArgumentParser(description="Run contrastive learning model.")
    parser.add_argument('--batch_size', type=int, default=25, help='Batch size for training and validation')
    parser.add_argument('--temperature', type=float, default=0.5, help='Temperature parameter for contrastive loss')
    parser.add_argument('--output_dir', type=str)
    return parser.parse_args()

args = get_args()
#-------------------------------------------------------------------------------------------------------------------

start_time = time.time()
print("start time:", start_time)

def default(val, def_val):
    return def_val if val is None else val

def device_as(t1, t2):
    """
    Moves t1 to the device of t2
    """
    return t1.to(t2.device)

def reproducibility(config):
    SEED = int(config.seed)
    torch.manual_seed(SEED)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    np.random.seed(SEED)
    if (config.cuda):
        torch.cuda.manual_seed(SEED)


def weights_update(model, checkpoint_path):
    checkpoint = torch.load(checkpoint_path)
    model_dict = model.state_dict()
    pretrained_dict = {k: v for k, v in checkpoint['state_dict'].items() if k in model_dict}
    model_dict.update(pretrained_dict)
    model.load_state_dict(model_dict)
    print(f'Checkpoint {checkpoint_path} was loaded')
    return model

#-------------------------------------------------------------------------------------------------------------------


def define_param_groups(model, weight_decay, optimizer_name):
    def exclude_from_wd_and_adaptation(name):
        if 'bn' in name:
            return True
        if optimizer_name == 'lars' and 'bias' in name:
            return True

    param_groups = [
        {
            'params': [p for name, p in model.named_parameters() if not exclude_from_wd_and_adaptation(name)],
            'weight_decay': weight_decay,
            'layer_adaptation': True,
        },
        {
            'params': [p for name, p in model.named_parameters() if exclude_from_wd_and_adaptation(name)],
            'weight_decay': 0.,
            'layer_adaptation': False,
        },
    ]
    return param_groups


 
class scContraLearn(pl.LightningModule):
    def __init__(self, config):
        super().__init__()
        self.config = config
        self.model = AddProjectionMLP(config)
        self.loss = ContrastiveLoss(config.batch_size, temperature=self.config.temperature)

    def forward(self, X):
        return self.model(X)

    def training_step(self, batch, batch_idx):
        x1, x2 = batch
        z1 = self.model(x1)
        z2 = self.model(x2)
        loss = self.loss(z1, z2)
        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)
        return loss

    def validation_step(self, batch, batch_idx):
        x1, x2 = batch
        z1 = self.model(x1)
        z2 = self.model(x2)
        loss = self.loss(z1, z2)
        self.log('val_loss', loss, on_epoch=True, prog_bar=True, logger=True)
        return {"val_loss": loss}

    def validation_epoch_end(self, outputs):
        avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()
        self.log('avg_val_loss', avg_loss,on_epoch=True, prog_bar=True, logger=True)


    def configure_optimizers(self):
        max_epochs = int(self.config.epochs)
        param_groups = define_param_groups(self.model, self.config.weight_decay, 'adamw')
        lr = self.config.lr
        optimizer = AdamW(param_groups, lr=lr, weight_decay=self.config.weight_decay)
        scheduler_warmup = LinearWarmupCosineAnnealingLR(optimizer, warmup_epochs=10, max_epochs=max_epochs, warmup_start_lr=0.0)
        return [optimizer], [scheduler_warmup]







class LossCallback(Callback):
    def __init__(self):
        super().__init__()
        self.train_losses = []
        self.val_losses = []
        self.avg_val_losses = []

    def on_train_epoch_end(self, trainer, pl_module, unused=None):  # Updated hook
        # This hook is called at the end of the training epoch
        # Since train_loss is logged as 'on_epoch' in training_step, we should retrieve it here
        train_loss = trainer.callback_metrics.get('train_loss')
        if train_loss is not None:
            self.train_losses.append(train_loss.item())

    def on_validation_epoch_end(self, trainer, pl_module):  # Updated hook
        # This hook is called at the end of the validation epoch
        val_loss = trainer.callback_metrics.get('val_loss')
        avg_val_loss = trainer.callback_metrics.get('avg_val_loss')
        if val_loss is not None:
            self.val_losses.append(val_loss.item())
        if avg_val_loss is not None:
            self.avg_val_losses.append(avg_val_loss.item())


#-------------------------------------------------------------------------------------------------------------------
#--------------------------------------------------Training Step----------------------------------------------------

class Hparams:
    def __init__(self):
        self.input_dim = 2000  # number of genes
        self.hidden_dims = [1024, 512, 256, 128, 64]  # various hidden layer sizes
        self.embedding_size = 32  # size of the output embeddings
        
        self.epochs = 220  # number of training epochs
        self.batch_size = args.batch_size  # batch size default 10 
        self.temperature = args.temperature # temperature parameter for contrastive loss default 0.5
        self.train_test_ratio = 0.8  # ratio for splitting train/test data
        
        self.seed = 3407  # seed for numpy, PyTorch (reproducibility)
        self.batch_seed = 17  # seed for creating batches
        self.random_seed = 42  # seed for the Python 'random' module (data shuffling)
        self.train_test_seed = 42  # seed for splitting train/test data

        self.gradient_accumulation_steps = 5  # number of gradient accumulation steps
        self.lr = 3e-4  # learning rate
        self.weight_decay = 1e-6  # weight decay for regularization

        self.cuda = True  # whether to use CUDA
        self.load = False  # whether to load a saved model
        self.save = "./saved_models/"  # path to save models
        self.checkpoint_path = './scContrastiveLearn.ckpt'  # path to checkpoint file
        self.out_dir = args.output_dir

#-------------------------------------------------------------------------------------------------------------------


"""## Training main logic"""

from pytorch_lightning import Trainer
import os
from pytorch_lightning.callbacks import GradientAccumulationScheduler
from pytorch_lightning.callbacks import ModelCheckpoint
# from torchvision.models import  resnet18


available_gpus = len([torch.cuda.device(i) for i in range(torch.cuda.device_count())])
save_model_path = os.path.join(os.getcwd(), "saved_models/")
print('available_gpus:',available_gpus)
filename='scContrastiveLearn_adam_'
resume_from_checkpoint = False
train_config = Hparams()

reproducibility(train_config)
save_name = filename + '.ckpt'
#-------------------------------------------------------------------------------------------------------------------

model = scContraLearn(train_config)
#-------------------------------------------------DataLoading-------------------------------------------------------
print("-------------------------------------------scContrastive Learning---------------------------------------------------")
print("#----------------------------------------------Hyper Parameters-----------------------------------------------------")
print("batch_size: ", train_config.batch_size)
print("temperature: " , train_config.temperature)
print("nuumber of epochs: ", train_config.epochs)
print("train_test_ratio: ", train_config.train_test_ratio)
print("input_dim: ", train_config.input_dim)
print("hidden_dims: ", train_config.hidden_dims)
print("embedding_size: ", train_config.embedding_size)


print("#-------------------------------------------------DataLoading-------------------------------------------------------")


random.seed(train_config.train_test_seed) 

larry_dataset, lineage_info, num_batch = LD.Larry_DataLoader(train_config.input_dim,train_config.batch_size, train_config.batch_seed)

# Select random batches for train and validation
train_batch_keys = random.sample(list(larry_dataset.keys()), int(train_config.train_test_ratio*num_batch))

train_batch = {key: larry_dataset[key] for key in train_batch_keys}
val_batch = {key: larry_dataset[key] for key in larry_dataset if key not in train_batch_keys}

train_dataset = ds.SCDataset(batches=train_batch)
val_dataset = ds.SCDataset(batches=val_batch)

train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=train_config.batch_size, shuffle=False, num_workers=1) #num_workers=cpu_count()//2
val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=train_config.batch_size, shuffle=False, num_workers=1) #num_workers=cpu_count()//2

print("----------------------train_val_dataloader------------------")
print(f"number of total batch: {len(larry_dataset.keys())}")
print(f"number of training batch: {len(train_batch.keys())}")
print(f"number of validation batch: {len(val_batch.keys())}")

# split lineage info for train and validation set 

train_batch_indices = []
for key in train_batch_keys:
    train_batch_indices.extend(range((key - 1) * train_config.batch_size, key * train_config.batch_size))

# Convert selected_indices to array for advanced indexing
train_batch_indices = np.array(train_batch_indices)
val_batch_indices = np.delete(np.arange(num_batch * train_config.batch_size), train_batch_indices)

train_lineage_info = lineage_info[train_batch_indices]
val_lineage_info = lineage_info[val_batch_indices]
print("-------------------train_val_lineage_info-------------------")
print(f"number of total batch{lineage_info.shape}")
print(f"number of training batch{train_lineage_info.shape}")
print(f"number of validation batch {val_lineage_info.shape}")


# save the lineage info for UMAP plotting
np.save(train_config.out_dir+ f'/lineage_info_bs{train_config.batch_size}_tau{train_config.temperature}.npy', lineage_info)
np.save(train_config.out_dir+ f'/train_lineage_info_bs{train_config.batch_size}_tau{train_config.temperature}.npy', train_lineage_info)
np.save(train_config.out_dir+ f'/val_lineage_info_bs{train_config.batch_size}_tau{train_config.temperature}.npy', val_lineage_info)



#-------------------------------------------------------------------------------------------------------------------
print("#-------------------------------------------------Training-------------------------------------------------------")

accumulator = GradientAccumulationScheduler(scheduling={0: train_config.gradient_accumulation_steps})

checkpoint_callback = ModelCheckpoint(
    filename=filename,
    dirpath=save_model_path,
    save_last=True,
    save_top_k=2,
    monitor='avg_val_loss',  # Monitoring 'avg_val_loss' which is logged in 'validation_epoch_end'
    mode='min'
)

loss_callback = LossCallback()


# Setup Trainer
trainer = Trainer(
    callbacks=[accumulator, checkpoint_callback, loss_callback],
    gpus=available_gpus,
    max_epochs=train_config.epochs,
    check_val_every_n_epoch=1, 
    resume_from_checkpoint=train_config.checkpoint_path if resume_from_checkpoint else None
)


# Fitting model
trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)

# Saving checkpoint
trainer.save_checkpoint(save_name)

# Saving loss
train_losses = np.array(loss_callback.train_losses)
val_losses = np.array(loss_callback.val_losses)
avg_val_losses = np.array(loss_callback.avg_val_losses)  # Convert list to numpy array

# Save to files
np.save(train_config.out_dir+ f'/train_losses_bs{train_config.batch_size}_tau{train_config.temperature}.npy', train_losses)
np.save(train_config.out_dir+ f'/val_losses_bs{train_config.batch_size}_tau{train_config.temperature}.npy', val_losses)
np.save(train_config.out_dir+ f'/avg_val_losses_bs{train_config.batch_size}_tau{train_config.temperature}.npy', avg_val_losses)



#-------------------------------------Extract Features of train_loader generated by the base encoder-------------------------------

print("#--------------------------------------------Feature Extracting(pairs)------------------------------------------------------")
model.eval()  # Set the model to evaluation mode
model.to('cuda' if torch.cuda.is_available() else 'cpu')  # Move model to the appropriate device


##-----------------------Extract Features generated by the base encoder for cell pairs-----------------------------

features_list_X = []
features_list_Y = []
for batch in train_loader:  
    X, Y = batch
    X = X.to(next(model.parameters()).device)  # Ensure X is on the correct device
    Y = Y.to(next(model.parameters()).device)
    with torch.no_grad():  # No need to compute gradients
        batch_features_X = model.model.get_features(X)  # Extract features
        batch_features_Y = model.model.get_features(Y)
    features_list_X.append(batch_features_X.cpu().detach().numpy())  # Store features as NumPy array
    features_list_Y.append(batch_features_Y.cpu().detach().numpy())

# Concatenate all batch features into a single NumPy array
features_X = np.concatenate(features_list_X, axis=0)
features_Y = np.concatenate(features_list_Y, axis=0)

print("Shape of the feature representation generated by the base encoder:", features_X.shape, features_Y.shape)
np.save(train_config.out_dir+f'/scBaseEncoderFeat_X_bs{train_config.batch_size}_tau{train_config.temperature}.npy', features_X)
np.save(train_config.out_dir+f'/scBaseEncoderFeat_Y_bs{train_config.batch_size}_tau{train_config.temperature}.npy', features_Y)


##------------------------------Extract Features generated by the base encoder for cells----------------------------
print("#--------------------------------------------Feature Extracting(pairs)------------------------------------------------------")

adata_subset = ad.read_h5ad('/home/users/syang71/Dataset/Larry_41201_2000.h5ad')
count_matrix = adata_subset.X
count_matrix_arr = count_matrix.toarray()
count_matrix_th = torch.from_numpy(count_matrix_arr)
dataset_cell = TensorDataset(count_matrix_th)
data_loader_all = torch.utils.data.DataLoader(dataset_cell, batch_size=train_config.batch_size, shuffle=False, num_workers=1,drop_last=False)
print("num of batches for all cells (not cell pairs):", len(data_loader_all))


features_list_Z = []

for batch in data_loader_all:  
    Z = batch[0]
    Z = Z.to(next(model.parameters()).device)  
    with torch.no_grad():  # No need to compute gradients
        batch_features_Z = model.model.get_features(Z)  # Extract features
        
    features_list_Z.append(batch_features_Z.cpu().detach().numpy())  # Store features as NumPy array

# Concatenate all batch features into a single NumPy array
features_Z = np.concatenate(features_list_Z, axis=0)


print("Shape of the feature representation generated by the base encoder:", features_Z.shape)
np.save(train_config.out_dir+ f'/scBaseEncoderFeat_Z_bs{train_config.batch_size}_tau{train_config.temperature}.npy', features_Z)


#-------------------------------------------------------------------------------------------------------------------

"""## Save only backbone weights from Resnet18 that are only necessary for fine tuning"""
model_pl = scContraLearn(train_config)
model_pl = weights_update(model_pl, "scContrastiveLearn_adam_.ckpt")

baseencoder_backbone_weights = model_pl.model.base_encoder.state_dict()
# # Saving base encoder weights
# base_encoder_weights = model_pl.model.base_encoder.state_dict()
# torch.save(base_encoder_weights, 'base_encoder_weights.ckpt')

# # Saving projection head weights
# projection_head_weights = model_pl.model.projection.state_dict()
# torch.save(projection_head_weights, 'projection_head_weights.ckpt')

print(baseencoder_backbone_weights)
torch.save({
            'model_state_dict': baseencoder_backbone_weights,
            }, 'baseencoder_weights.ckpt')

#-------------------------------------------------------------------------------------------------------------------

end_time = time.time()
print("end time:", end_time)
print(f"Execution time: {end_time - start_time} seconds")