{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1d0173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/titan_env_py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------------------\n",
    "# 1) Wrap f and g together\n",
    "# ----------------------------\n",
    "class LCLFG(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, f, g):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.g = g\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, G]\n",
    "        h = self.f(x)\n",
    "        z = self.g(h)\n",
    "        return z  # [B, Dproj]\n",
    "\n",
    "model_fg = LCLFG(f, g).eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Precompute all z and lineage centroids\n",
    "# ----------------------------\n",
    "@torch.no_grad()\n",
    "def compute_z_and_centroids(model_fg, X, lineage_ids, device=\"cuda\", batch_size=1024):\n",
    "    model_fg = model_fg.to(device)\n",
    "    X = X.to(device)\n",
    "\n",
    "    Z = []\n",
    "    for i in range(0, X.shape[0], batch_size):\n",
    "        z = model_fg(X[i:i+batch_size])\n",
    "        Z.append(z.detach().cpu())\n",
    "    Z = torch.cat(Z, dim=0)  # [N, D]\n",
    "\n",
    "    # map lineage -> indices\n",
    "    lineage_to_idx = {}\n",
    "    for i, lid in enumerate(lineage_ids):\n",
    "        lineage_to_idx.setdefault(lid, []).append(i)\n",
    "\n",
    "    # compute centroid per lineage\n",
    "    centroids = {}\n",
    "    for lid, idxs in lineage_to_idx.items():\n",
    "        centroids[lid] = Z[idxs].mean(dim=0)  # [D]\n",
    "        centroids[lid] = centroids[lid] / (centroids[lid].norm() + 1e-12)\n",
    "\n",
    "    return Z, centroids, lineage_to_idx\n",
    "\n",
    "Z_cpu, centroids, lineage_to_idx = compute_z_and_centroids(model_fg, X, lineage_ids)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Define a scalar function F(x) = cosine(z(x), centroid[lineage])\n",
    "#    Captum wants forward() -> scalar per example\n",
    "# ----------------------------\n",
    "class CosineToCentroid(torch.nn.Module):\n",
    "    def __init__(self, model_fg, centroid_vec):\n",
    "        super().__init__()\n",
    "        self.model_fg = model_fg\n",
    "        self.register_buffer(\"centroid\", centroid_vec.clone())\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.model_fg(x)  # [B, D]\n",
    "        z = z / (z.norm(dim=1, keepdim=True) + 1e-12)\n",
    "        # cosine with centroid -> [B]\n",
    "        return (z * self.centroid.unsqueeze(0)).sum(dim=1)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Run IG for a set of cells in one lineage\n",
    "# ----------------------------\n",
    "def run_ig_for_lineage(\n",
    "    model_fg, X, idxs, centroid_vec, baseline=\"zero\",\n",
    "    n_steps=64, method=\"gausslegendre\", device=\"cuda\"\n",
    "):\n",
    "    model_fg = model_fg.to(device).eval()\n",
    "    X = X.to(device)\n",
    "\n",
    "    # baseline tensor\n",
    "    if baseline == \"zero\":\n",
    "        base = torch.zeros((1, X.shape[1]), device=device)\n",
    "    elif baseline == \"mean\":\n",
    "        base = X.mean(dim=0, keepdim=True).detach()\n",
    "    else:\n",
    "        raise ValueError(\"baseline must be 'zero' or 'mean'\")\n",
    "\n",
    "    # Build scalar model\n",
    "    scalar_model = CosineToCentroid(model_fg, centroid_vec.to(device)).eval()\n",
    "    ig = IntegratedGradients(scalar_model)\n",
    "\n",
    "    # Gather inputs\n",
    "    inputs = X[idxs].detach().requires_grad_(True)\n",
    "\n",
    "    # Captum supports broadcasting baselines to batch\n",
    "    attributions, delta = ig.attribute(\n",
    "        inputs,\n",
    "        baselines=base,\n",
    "        n_steps=n_steps,\n",
    "        method=method,\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "    # attributions: [B, G], delta: [B]\n",
    "    return attributions.detach().cpu(), delta.detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91b80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example: pick one lineage and run IG on up to 200 cells from it\n",
    "some_lineage = list(lineage_to_idx.keys())[0]\n",
    "idxs = lineage_to_idx[some_lineage][:200]\n",
    "centroid_vec = centroids[some_lineage]  # [D]\n",
    "attr, delta = run_ig_for_lineage(model_fg, X, idxs, centroid_vec, baseline=\"zero\")\n",
    "print(\"attr shape:\", attr.shape, \"delta mean:\", delta.mean().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titan_env_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
